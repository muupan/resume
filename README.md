# Yasuhiro Fujita

- Email: muupan@gmail.com

## Research interests

- Reinforcement learning

## Publications

[Google Scholar](https://scholar.google.com/citations?user=vfOynukAAAAJ)

- **PLaMo-100B: A Ground-Up Language Model Designed for Japanese Proficiency**
  - Preferred Elements, Inc.
  - Technical paper, 2024. [arXiv](https://arxiv.org/abs/2410.07563)
- **Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis**
  - Tianhan Xu, Yasuhiro Fujita, Eiichi Matsumoto 
  - CVPR, 2022. [arXiv](https://arxiv.org/abs/2201.01683)
- **ChainerRL:  ChainerRL: A Deep Reinforcement Learning Library**
  - Yasuhiro Fujita, Prabhat Nagarajan, Toshiki Kataoka, Takahiro Ishikawa
  - Journal of Machine Learning Research, 22(77), 1-14. [arXiv](https://arxiv.org/abs/1912.03905v2) [code](https://github.com/chainer/chainerrl)
- **Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators**
  - Yasuhiro Fujita, Kota Uenishi, Avinash Ummadisingu, Prabhat Nagarajan, Shimpei Masuda, Mario Ynocente Castro
  - IROS, 2020. [arXiv](http://arxiv.org/abs/2007.08082)
- **Learning Latent State Spaces for Planning through Reward Prediction**
  - Aaron Havens, Yi Ouyang, Prabhat Nagarajan, Yasuhiro Fujita
  - NeurIPS Deep Reinforcement Learning Workshop, 2019. [arXiv](https://arxiv.org/abs/1912.04201)
- **A Wrapped Normal Distribution on Hyperbolic Space for Gradient-Based Learning**
  - Yoshihiro Nagano, Shoichiro Yamaguchi, Yasuhiro Fujita, Masanori Koyama
  - ICML, 2019. [arXiv](https://arxiv.org/abs/1902.02992)
- **Toward Onboard Control System for Mobile Robots via Deep Reinforcement Learning**
  - Megumi Miyashita, Shirou Maruyama, Yasuhiro Fujita, Mitsuru Kusumoto, Tobias Pfeiffer, Eiichi Matsumoto, Ryosuke Okuta, Daisuke Okanohara
  - NeurIPS Deep RL Workshop, 2018. [pdf](https://drive.google.com/file/d/0B_utB5Y8Y6D5d0NFZ25CdGluRDVGTlVyMHh2Q1g4NXZNbTJJ/view)
- **Model-Based Reinforcement Learning via Meta-Policy Optimization**
  - Ignasi Clavera, Jonas Rothfuss, John Schulman, Yasuhiro Fujita, Tamim Asfour, Pieter Abbeel
  - CoRL, 2018. [arXiv](https://arxiv.org/abs/1809.05214)
- **Clipped Action Policy Gradient**
  - Yasuhiro Fujita, Shin-ichi Maeda
  - ICML, 2018. [arXiv](https://arxiv.org/abs/1802.07564) [code](https://github.com/pfnet-research/capg) [slides](https://www.slideshare.net/mooopan/clipped-action-policy-gradient-107793858)

## Translations

- Co-translated into Japanese [Algorithms of Reinforcement Learning](https://sites.ualberta.ca/~szepesva/rlbook.html) -> [速習 強化学習 ―基礎理論とアルゴリズム―](https://www.kyoritsu-pub.co.jp/book/b10003874.html)
- Co-translated into Japanese [Reinforcement Learning: An Introduction (second edition)](http://incompleteideas.net/book/the-book-2nd.html) -> [強化学習 (第2版)](https://www.morikita.co.jp/books/mid/082662)

## Code

- [ChainerRL](https://github.com/chainer/chainerrl): A deep RL library in Python and Chainer
- [PFRL](https://github.com/pfnet/pfrl): A deep RL library in Python and PyTorch
- [async-rl](https://github.com/muupan/async-rl): An A3C implementation in Python and Chainer
- [DQN-in-the-Caffe](https://github.com/muupan/dqn-in-the-caffe): A DQN implementation in C++ and Caffe

## Work experience

- Engineer at Preferred Networks, Inc. (April 2015 - Present)

  - Research and development in machine learning for industrial applications: autonomous driving, robotics, computer graphics, and quantitative finance.
  - OSS development for reinforcement learning: [ChainerRL](https://github.com/chainer/chainerrl) and [PFRL](https://github.com/pfnet/pfrl).
  
## Professional activities

- Program committee: Deep Reinforcement Learning Workshop at NeurIPS (2018-2022)
- Guest lecturer: RL part of 先端人工知能論II at the University of Tokyo (2016-2018)

## Education

- M.S. Information Science and Technology (April 2013 - March 2015)

  - Graduate School of Information Science and Technology, The University of Tokyo
  - Thesis: “Automatic Feature Generation and Model Learning for General Game Players Based on Reinforcement Learning“
  
- B.S Engineering (April 2011 - March 2013)
